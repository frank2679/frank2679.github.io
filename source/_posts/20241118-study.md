---
title: study notes
date: 2024-11-18 13:46:02
tags: [ML, LLM]
---

- [1. 概览](#1-概览)
  - [1.1. 目标](#11-目标)
  - [1.2. 资源](#12-资源)
- [2. vLLM](#2-vllm)
- [3. 分布式](#3-分布式)
  - [3.1. 概览](#31-概览)
  - [3.2. 消息通信](#32-消息通信)
- [4. pytorch](#4-pytorch)
- [5. LLVM](#5-llvm)
- [6. cuda / supa](#6-cuda--supa)
- [7. 性能调优](#7-性能调优)
  - [7.1. 理论性能分析](#71-理论性能分析)
  - [7.2. 优化策略](#72-优化策略)
  - [7.3. 性能优化工具](#73-性能优化工具)


# 1. 概览


## 1.1. 目标

能够部署 E2E 业务，提升自己的开发效率，以及做一个产品实现商业闭环。

## 1.2. 资源

- [头歌实践教学平台](https://www.educoder.net/)
- [ustc, zhangyu, 编译原理课程 resource](http://staff.ustc.edu.cn/~yuzhang/compiler/2023f/nsec/index.html)

大佬
- [Dennis Ritchie](https://www.bell-labs.com/usr/dmr/www/)
- [Brian Kernighan](https://www.cs.princeton.edu/~bwk/)

# 2. vLLM

[what is vLLM?](https://www.hopsworks.ai/dictionary/vllm)
[Qwen doc, 2.5 都被 vLLM 支持](https://qwen.readthedocs.io/zh-cn/latest/deployment/vllm.html)

vLLM 的优点
- 易于使用
- 具有最先进的服务吞吐量
- 高效 kv cache 内存管理（通过 pagedAttention 实现）
- 连续批处理输入请求
- 优化的 CUDA 内核

核心概念
- 词汇表总规模 151665

# 3. 分布式

## 3.1. 概览
并行算法
- 模型并行
  - 训练精度等同单卡
  - 切分模型，不同机器跑不同部分
  - 要求设备间数据传输快
  - 典型场景：单机多卡
- 数据并行
  - 训练精度低于单卡
  - 切分batch
  - 每个 device 存放并运行完整模型
  - 集群主流算法
![](model_paral.png)

![](data_paral.png)

数据并行 all reduce 算法
- NVIDIA
  - NCCL 2.3 hierarchical ring allreduce
  - NCCL 2.4 double tree all reduce
- TPU
  - 2D torus ring

## 3.2. 消息通信
MPI：起源于科学计算
NCCL(NVIDIA Collective Communications Library) API 与 MPI 类似

操作包括
- all reduce
- reduce
- broadcast
- allgather
- reducescatter

all reduce
ring all reduce
- 每个卡上数据切块，数量与卡数量相等
- 每次 loop 每个卡只算某个分块求和，loop 多次后每个卡上最终求和的部分分块

特征
- 扩展性较差
  - 分块受 GPU 数量影响，数量增加延时增加

扩展性问题解决——结构化 ring
- 2D torus TPU v3，3步
  - ![alt text](torus_alg.png)
- hyrid ring, NCCL 2.3
  - 2步，![alt text](hibrid_alg.png)
  - 3步，![alt text](binary_tree_alg.png)


# 4. pytorch

JIT，torchscript

- [知乎, PyTorch系列「一」PyTorch JIT —— trace/ script的代码组织和优化方法](https://zhuanlan.zhihu.com/p/410507557)
- [github, JIT overview](https://github.com/pytorch/pytorch/blob/main/torch/csrc/jit/OVERVIEW.md)
- [pytorch, torchscript](https://pytorch.org/docs/main/jit.html)
- [lecture, 面向机器学习的编译](http://staff.ustc.edu.cn/~yuzhang/compiler/2019f/lectures/c4ml-6in1.pdf)

eager mode 易于调试，但是不利于性能优化，JIT 模式将原本 eager mode 表达转变成一个计算图，进行优化和序列化。（向TF靠拢）


# 5. LLVM
- [电子书 getting-started-with-llvm-core-libraries.pdf, github有其他资源](https://github.com/firmianay/security-paper/blob/master/Compiler/Getting_Started_with_LLVM_Core_Libraries/Getting%20Started%20with%20LLVM%20Core%20Libraries.pdf)
- [中文版，getting-started-with-llvm-core-libraries.pdf](https://getting-started-with-llvm-core-libraries-zh-cn.readthedocs.io/zh-cn/latest/)

代码 https://github.com/llvm/llvm-project/tree/release/10.x
 
官方文档汇总 https://llvm.org/docs/
官方培训材料 http://llvm.org/docs/tutorial/index.html
 
编程规范 https://llvm.org/docs/CodingStandards.html
编程指南 https://llvm.org/docs/ProgrammersManual.html 
 
后端编译器实现 http://llvm.org/docs/WritingAnLLVMBackend.html  
通用代码生成 http://llvm.org/docs/CodeGenerator.html
自定义扩展 https://llvm.org/docs/ExtendingLLVM.html
 
TableGen简介 http://llvm.org/docs/TableGen/index.html
FileCheck简介 https://llvm.org/docs/CommandGuide/FileCheck.html  
 
LLVM IR http://llvm.org/docs/LangRef.html
Writing a Pass http://llvm.org/docs/WritingAnLLVMPass.html 

Life of an instruction in LLVM https://eli.thegreenplace.net/2012/11/24/life-of-an-instruction-in-llvm/

# 6. cuda / supa


# 7. 性能调优

## 7.1. 理论性能分析

## 7.2. 优化策略

## 7.3. 性能优化工具

